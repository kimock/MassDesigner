import os
import torch
from torch_geometric.data import Batch
from Model.models import Generator
from util_eval import save_output, evaluate_best_of_n
from util_graph import get_program_ratio
from train_args import make_args

import os
args = make_args()
if str(args.cuda) == -1:
    cuda = False
else:
    cuda = True
    os.environ['CUDA_VISIBLE_DEVICES'] = str(args.cuda)

# GPU ì„¤ì •í•˜ê¸° ì¿ ë‹¤ë©´ ì¿ ë‹¤ë¡œ ì„¤ì •
device_ids = list(range(torch.cuda.device_count())) if cuda else []
assert(args.batch_size % len(device_ids) == 0)
print('Using GPU {}'.format(os.environ['CUDA_VISIBLE_DEVICES']) if cuda else "Using CPU")
if cuda:
    print([torch.cuda.get_device_name(device_id) for device_id in device_ids])
print(args)
device = torch.device('cuda:'+str(device_ids[0]) if cuda else 'cpu')
# device = torch.device("cpu")
print(device)

# 2. ì €ì¥ëœ graph íŒŒì¼ ë¶ˆëŸ¬ì˜¤ê¸° (í•™ìŠµì— ì‚¬ìš©ëœ ì „ì²˜ë¦¬ëœ ë°ì´í„°)
graph = torch.load("Data/6types-processed_data/data022499.pt", map_location=device)
# ë‹¨ì¼ ë°ì´í„°ë¥¼ ë°°ì¹˜ë¡œ ê°ì‹¸ê¸° (follow_batch ì§€ì •)
follow_batch = ['program_target_ratio', 'program_class_feature', 'voxel_feature']
graph = Batch.from_data_list([graph], follow_batch=follow_batch).to(device)

# 2. ë…¸ì´ì¦ˆ ìƒì„± (í•™ìŠµ ì‹œ ì‚¬ìš©í•œ ê°’ê³¼ ë™ì¼í•œ ì°¨ì›)
noise_dim = args.noise_dim  # ë””í´íŠ¸ëŠ” 32

# 3. í•™ìŠµëœ generator ë¡œë“œ
latent_dim = 128
generator = Generator(
    program_input_dim=graph.program_class_feature.shape[-1] + 1,  # story level í¬í•¨
    voxel_input_dim=graph.voxel_feature.shape[-1],
    hidden_dim=latent_dim,
    noise_dim=noise_dim,
    program_layer=4,
    voxel_layer=12,
    device=device
).to(device)

inference_dir = "inference"
# trained_id = "iccv2021"
# epoch_id = '70'
trained_id = "test"
epoch_id = '20'
trained_file = 'runs/{}/checkpoints/{}.ckpt'.format(trained_id, epoch_id)
# í•™ìŠµëœ ì²´í¬í¬ì¸íŠ¸ íŒŒì¼ì„ ë¡œë“œ (íŒŒì¼ ê²½ë¡œëŠ” ì‹¤ì œ ì²´í¬í¬ì¸íŠ¸ ê²½ë¡œë¡œ ìˆ˜ì •)
generator.load_state_dict(torch.load(trained_file), strict=True)
generator.eval()

raw_dir = "Data/6types-raw_data"       # ì›ë³¸ JSON íŒŒì¼ë“¤ì´ ì €ì¥ëœ í´ë” (global_graph_data, local_graph_data, voxel_data í´ë” í¬í•¨)
output_dir = f"Data/6types-output"        # ê²°ê³¼ë¥¼ ì €ì¥í•  í´ë”

import torch

def check_cross_edge_mappings(graph):
    """
    í”„ë¡œê·¸ë¨ ë…¸ë“œì™€ ë³µì…€ ë…¸ë“œ ê°„ì˜ cross-edge ì—°ê²° ìƒíƒœë¥¼ í™•ì¸í•˜ëŠ” í•¨ìˆ˜.
    """
    print("ğŸ“Œ í”„ë¡œê·¸ë¨ ë…¸ë“œ ìˆ˜:", graph.program_class_feature.shape[0])
    print("ğŸ“Œ ë³µì…€ ë…¸ë“œ ìˆ˜:", graph.voxel_feature.shape[0])
    
    print("ğŸ“Œ cross_edge_program_index_select:", graph.cross_edge_program_index_select.shape)
    print("ğŸ“Œ cross_edge_voxel_index_select:", graph.cross_edge_voxel_index_select.shape)

    # ì—°ê²° ë¹„ìœ¨ ê³„ì‚°
    program_indices = graph.cross_edge_program_index_select.cpu().numpy()
    voxel_indices = graph.cross_edge_voxel_index_select.cpu().numpy()
    
    print(f"ğŸ“Œ í”„ë¡œê·¸ë¨-ë³µì…€ ì—°ê²° ë¹„ìœ¨: {len(set(program_indices))} / {graph.program_class_feature.shape[0]}")
    print(f"ğŸ“Œ ë³µì…€-í”„ë¡œê·¸ë¨ ì—°ê²° ë¹„ìœ¨: {len(set(voxel_indices))} / {graph.voxel_feature.shape[0]}")

# ì‚¬ìš© ì˜ˆì‹œ
check_cross_edge_mappings(graph)

viz_dir = os.path.join(inference_dir, trained_id, epoch_id + "_", "output")

# 1.0ì— ê°€ê¹Œìš¸ìˆ˜ë¡ ë” ë‹¤ì–‘í•œ ê²°ê³¼ê°€ ë‚˜ì˜´. 
    # 0.7ì²˜ëŸ¼ ë‚®ì¶”ë©´ ë” ì¼ê´€ë˜ê³  ì•ˆì •ì ì¸ ê²°ê³¼ê°€ ë‚˜ì˜´.
truncated = False
if not truncated:
    trunc_num = 1.0
else:
    trunc_num = 0

# ì‹œê°í™” ì¶œë ¥í•  ì •ë³´ë¥¼ ì €ì¥í•  ë””ë ‰í† ë¦¬ ìƒì„±
graph = graph.to(device)

evaluate_best_of_n(graph, generator, raw_dir, output_dir, follow_batch, device, n_trials=100, trunc=trunc_num)



# program_z = torch.rand([graph.program_class_feature.shape[0], noise_dim]).to(device)
# voxel_z = torch.rand([graph.voxel_feature.shape[0], noise_dim]).to(device)
# out, soft_out, mask, att, max_out_program_index = generator(graph, program_z, voxel_z)
#     # 5. get_program_ratio() í˜¸ì¶œí•˜ì—¬ ì¶”ê°€ ì •ë³´ ê³„ì‚° (area_indexëŠ” í•™ìŠµ ì‹œ ì‚¬ìš©í•œ index, ì˜ˆì‹œë¡œ 6 ì‚¬ìš©)
# print(mask["hard"].sum())          # 0ì´ë©´ ëª¨ë“  voxelì´ êº¼ì ¸ ìˆëŠ” ìƒíƒœ
# print(mask["hard"][:10].T)         # ì•ìª½ 10ê°œ í™•ì¸

# normalized_program_class_weight, program_weight, FAR = get_program_ratio(graph, att["hard"], mask["hard"], area_index_in_voxel_feature=6)

#     # 6. ì €ì¥í•  í´ë” ì§€ì • (raw_dirì—ëŠ” ì›ë³¸ global, local, voxel JSON íŒŒì¼ë“¤ì´ ìˆì–´ì•¼ í•¨)
# raw_dir = "Data/6types-raw_data"       # ì›ë³¸ JSON íŒŒì¼ë“¤ì´ ì €ì¥ëœ í´ë” (global_graph_data, local_graph_data, voxel_data í´ë” í¬í•¨)
# output_dir = f"Data/6types-output"        # ê²°ê³¼ë¥¼ ì €ì¥í•  í´ë”
# if not os.path.exists(output_dir):
#     os.makedirs(output_dir)
#     # í•˜ìœ„ í´ë”ë“¤ë„ ì—†ìœ¼ë©´ ìƒì„± (save_output ë‚´ë¶€ì—ì„œ ìƒì„±í•˜ì§€ë§Œ, ë¯¸ë¦¬ í™•ì¸í•´ë„ ì¢‹ìŠµë‹ˆë‹¤.)
# for sub in ["global_graph_data", "local_graph_data", "voxel_data"]:
#     sub_dir = os.path.join(output_dir, sub)
#     if not os.path.exists(sub_dir):
#             os.makedirs(sub_dir)

#     # 7. ë°°ì¹˜ ì‚¬ì´ì¦ˆ (ì—¬ê¸°ì„œëŠ” ë‹¨ì¼ ë°ì´í„°ì´ë¯€ë¡œ 1)
# batch_size = 1

#     # 8. save_output í•¨ìˆ˜ í˜¸ì¶œí•˜ì—¬ ê²°ê³¼ ì €ì¥
#     # new_data_id_strsëŠ” ì„ íƒì‚¬í•­ì…ë‹ˆë‹¤.
# batch_all_g = save_output(batch_size, graph, normalized_program_class_weight, program_weight,
#                             FAR, max_out_program_index, out, follow_batch, raw_dir, output_dir)

# print("ì €ì¥ ì™„ë£Œ!")
